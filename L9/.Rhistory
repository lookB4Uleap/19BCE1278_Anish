plot(df[c("UrbanPop", "Rape")], col=result$cluster)
plot(df[,], col=result$cluster)
table(result$cluster, df)
#Load and view dataset
require("datasets")
data("iris") # load Iris Dataset
str(iris) #view structure of dataset
#2. Display the Statistical Summary of the dataset
summary(iris) #view statistical summary of dataset
head(iris) #view top  rows of dataset
#3. Apply the preprocessing to remove the class attribute eg., Species , since #clustering is a type of unsupervised learning
#Preprocess the dataset
#Since clustering is a type of Unsupervised Learning, we would not require Class Label(output) during
#execution of our algorithm. We will, therefore, remove Class Attribute “Species”
#and store it in another variable.
#We would then normalize the attributes between 0 and 1 using our own function.
iris.new<- iris[,c(1,2,3,4)]
iris.class<- iris[,"Species"]
head(iris.new)
head(iris.class)
#4. Create a function to normalize the data before clustering
# Normalization
normalize <- function(x){
return ((x-min(x))/(max(x)-min(x)))
}
iris.new$Sepal.Length<- normalize(iris.new$Sepal.Length)
iris.new$Sepal.Width<- normalize(iris.new$Sepal.Width)
iris.new$Petal.Length<- normalize(iris.new$Petal.Length)
iris.new$Petal.Width<- normalize(iris.new$Petal.Width)
head(iris.new)
#5. Apply k-means clustering algorithm with k = 3
result<- kmeans(iris.new,3) #aplly k-means algorithm with no. of centroids(k)=3
#6. Find the number of records in each cluster
result$size # gives no. of records in each cluster
#7. Display the cluster center data point values
result$centers # gives value of cluster center datapoint value(3 centers for k=3)
#8. Display the cluster vector showing the cluster where each record falls
result$cluster #gives cluster vector showing the cluster where each record falls
# Verify results of clustering
par(mfrow=c(2,2), mar=c(5,4,2,2))
#9. Plot to see how Sepal.Length and Sepal.Width data points have been distributed in clusters
plot(iris.new[c(1,2)], col=result$cluster)# Plot to see how Sepal.Length and Sepal.Width data points have been distributed in clusters
#10. Plot to see how Sepal.Length and Sepal.Width data points have been distributed originally as per "class" attribute in dataset
plot(iris.new[c(1,2)], col=iris.class)# Plot to see how Sepal.Length and Sepal.Width data points have been distributed originally as per "class" attribute in dataset
#11.Plot to see how Petal.Length and Petal.Width data points have been distributed in clusters
plot(iris.new[c(3,4)], col=result$cluster)# Plot to see how Petal.Length and Petal.Width data points have been distributed in clusters
#12.Plot to see how Petal.Length and Petal.Width data points have been distributed originally as per "class" attribute in dataset
plot(iris.new[c(3,4)], col=iris.class)
result$cluster <- as.factor(result$cluster)
#13.  Install the package ggplot2 and import it.
library(ggplot2)
#14. Plot the clusterresults using ggplot
ggplot(iris.new, aes(Petal.Length, Petal.Width, color = result$cluster)) + geom_point()
plot(iris.new[c("Sepal.Length", "Sepal.Width")], col=result$cluster)
#15. Display the clustering results with all parameters
#points(result$centers[,c("Sepal.Length", "Sepal.Width")], col=1:3, pch=23, cex=3)
plot(iris.new[,], col=result$cluster)
#16. Display the results in table
table(result$cluster,iris.class) # Result of table shows that Cluster 1 corresponds to Virginica, Cluster 2 corresponds to Versicolor and Cluster 3 to Setosa.
#16. Display the results in table
table(result$cluster,iris.class) # Result of table shows that Cluster 1 corresponds to Virginica, Cluster 2 corresponds to Versicolor and Cluster 3 to Setosa.
length(result)
length(df)
df <- USArrests
df <- na.omit(df)
head(df)
summary(df)
normalize <- function(x){
return ((x-min(x))/(max(x)-min(x)))
}
df$Murder <- normalize(df$Murder)
df$Assault <- normalize(df$Assault)
df$UrbanPop <- normalize(df$UrbanPop)
df$Rape <- normalize(df$Rape)
head(df)
result<- kmeans(df, 4)
par(mfrow=c(2,2), mar=c(5,4,2,2))
plot(df[c(1,2)], col=result$cluster)
result$cluster <- as.factor(result$cluster)
library(ggplot2)
ggplot(df, aes(Murder, Assault, color = result$cluster)) + geom_point()
plot(df[c("UrbanPop", "Rape")], col=result$cluster)
plot(df[,], col=result$cluster)
table(result$cluster, df)
length(result)
length(result$cluster)
length(df)
result$cluster
df[1]
table(result$cluster)
ncol(df)
nrow(df)
table(result$cluster, 1:4)
library(ggplot2)
ggplot(df, aes(Murder, Assault, color = result$cluster)) + geom_point()
plot(df[c("UrbanPop", "Rape")], col=result$cluster)
plot(df[,], col=result$cluster)
table(result$cluster, c(1,2,3,4))
iris.class
install.packages("cluster.datasets")
library(cluster.datasets)
library(cluster.datasets)
df <- USPersonalExpenditure
df <- na.omit(df)
head(df)
summary(df)
library(cluster.datasets)
df <- USPersonalExpenditure
df <- na.omit(df)
head(df)
summary(df)
head(df)
df <- data("animal.cluster.trees")
df <- na.omit(df)
head(df)
summary(df)
library(cluster.datasets)
df <- data("animal.cluster.trees")
df <- na.omit(df)
head(df)
summary(df)
library(cluster.datasets)
df <- data("animal.cluster.trees")
df <- na.omit(df)
head(df)
summary(df)
data("animal.cluster.trees")
df <- animal.cluster.trees
library(cluster.datasets)
data("animal.cluster.trees")
df <- animal.cluster.trees
df <- na.omit(df)
head(df)
summary(df)
df$symbol
library(cluster.datasets)
data("animal.cluster.trees")
df <- animal.cluster.trees
df <- na.omit(df)
head(df)
summary(df)
df.class <- iris[, "symbol"]
library(cluster.datasets)
data("animal.cluster.trees")
df <- animal.cluster.trees
df <- na.omit(df)
head(df)
summary(df)
df.class <- df[, "symbol"]
library(cluster.datasets)
data("animal.cluster.trees")
df <- animal.cluster.trees
df <- na.omit(df)
head(df)
summary(df)
df.class <- df[, "symbol"]
result<- kmeans(df[3,], 4)
df[2,]
df[,3]
df[]
df[c(c1,c2,c3,c4,c5,c6,c7,c8,c9)]
df[c("c1","c2","c3","c4","c5","c6","c7","c8","c9")]
normalize <- function(x){
return ((x-min(x))/(max(x)-min(x)))
}
df[c("c.1","c.2","c.3","c.4","c.5","c.6","c.7","c.8","c.9")]
df[,1:]
df[3,]
df[3,3:ncol(df)]
df[,3:ncol(df)]
df <- df[,3:ncol(df)]
result<- kmeans(df, 4)
result<- kmeans(df, 13)
df.class
summary(df)
head(df)
df
library(cluster.datasets)
data("all.mammals.milk.1956")
library(cluster.datasets)
data("all.mammals.milk.1956")
df <- all.mammals.milk.1956
df <- na.omit(df)
head(df)
summary(df)
df.class <- df[, "symbol"]
df.class <- df[, "name"]
df.class
df <- USArrests
df <- na.omit(df)
head(df)
summary(df)
normalize <- function(x){
return ((x-min(x))/(max(x)-min(x)))
}
df$Murder <- normalize(df$Murder)
df$Assault <- normalize(df$Assault)
df$UrbanPop <- normalize(df$UrbanPop)
df$Rape <- normalize(df$Rape)
head(df)
result<- kmeans(df, 4)
par(mfrow=c(2,2), mar=c(5,4,2,2))
plot(df[c(1,2)], col=result$cluster)
result$cluster <- as.factor(result$cluster)
library(ggplot2)
ggplot(df, aes(Murder, Assault, color = result$cluster)) + geom_point()
plot(df[c("UrbanPop", "Rape")], col=result$cluster)
plot(df[,], col=result$cluster)
table(result$cluster, c(1,2,3,4))
library(ggplot2)
ggplot(df, aes(Murder, Assault, color = result$cluster)) + geom_point()
plot(df[c("UrbanPop", "Rape")], col=result$cluster)
plot(df[,], col=result$cluster)
install.packages("animation")
library(animation)
install.packages("animation")
library(animation)
library(animation)
library(animation)
install.packages("animation")
install.packages("animation")
library(animation)
km1<-kmeans.ani(df,3)
#18. Import factoextra package and visualize the cluster result
library(factoextra) # clustering algorithms & visualization
fviz_cluster(result, data = df)
#19. Explore the cluster analysis result with various value of k like 3,4,5
k2 <- kmeans(df, centers = 2, nstart = 25)
k3 <- kmeans(df, centers = 3, nstart = 25)
k4 <- kmeans(df, centers = 4, nstart = 25)
k5 <- kmeans(df, centers = 5, nstart = 25)
install.packages("gridExtra")
# plots to compare
p1 <- fviz_cluster(k2, geom = "point", data = df) + ggtitle("k = 2")
p2 <- fviz_cluster(k3, geom = "point",  data = df) + ggtitle("k = 3")
p3 <- fviz_cluster(k4, geom = "point",  data = df) + ggtitle("k = 4")
p4 <- fviz_cluster(k5, geom = "point",  data = df) + ggtitle("k = 5")
library(gridExtra)
grid.arrange(p1, p2, p3, p4, nrow = 2)
datasets(iris)
dataset(iris)
df <- iris
df <- iris
df <- na.omit(df)
head(df)
summary(df)
result<- kmeans(df, 3)
normalize <- function(x){
return ((x-min(x))/(max(x)-min(x)))
}
df$Sepal.Length <- normalize(df$Sepal.Length)
df$Sepal.Width <- normalize(df$Sepal.Width)
df$Petal.Length <- normalize(df$Petal.Length)
df$Petal.Width <- normalize(df$Petal.Width)
head(df)
result<- kmeans(df, 3)
df <- iris
df <- na.omit(df)
df <- df[,c(1,2,3,4)]
df.class <- df[,"Species"]
df <- iris
df <- na.omit(df)
df.class <- df[,"Species"]
df <- df[,c(1,2,3,4)]
head(df)
summary(df)
normalize <- function(x){
return ((x-min(x))/(max(x)-min(x)))
}
df$Sepal.Length <- normalize(df$Sepal.Length)
df$Sepal.Width <- normalize(df$Sepal.Width)
df$Petal.Length <- normalize(df$Petal.Length)
df$Petal.Width <- normalize(df$Petal.Width)
head(df)
result<- kmeans(df, 3)
result<- kmeans(df, 3)
result$cluster
result$centers
result$size
par(mfrow=c(2,2), mar=c(5,4,2,2))
plot(df[c(1,2)], col=result$cluster)
result$cluster <- as.factor(result$cluster)
library(ggplot2)
ggplot(iris.new, aes(Petal.Length, Petal.Width, color = result$cluster)) + geom_point()
library(ggplot2)
ggplot(df, aes(Petal.Length, Petal.Width, color = result$cluster)) + geom_point()
plot(df[c("Sepal.Length", "Sepal.Width")], col=result$cluster)
plot(df[,], col=result$cluster)
result<- kmeans(df, 3)
result$cluster
result$centers
result$size
par(mfrow=c(2,2), mar=c(5,4,2,2))
plot(iris.new[c(1,2)], col=result$cluster)
result<- kmeans(df, 3)
result$cluster
result$centers
result$size
par(mfrow=c(2,2), mar=c(5,4,2,2))
plot(df[c(1,2)], col=result$cluster)
plot(df[c(1,2)], col=iris.class)
result<- kmeans(df, 3)
result$cluster
result$centers
result$size
par(mfrow=c(2,2), mar=c(5,4,2,2))
plot(df[c(1,2)], col=result$cluster)
plot(df[c(1,2)], col=df.class)
plot(df[c(3,4)], col=df.class)
result$cluster <- as.factor(result$cluster)
library(animation)
km1<-kmeans.ani(df,3)
#18. Import factoextra package and visualize the cluster result
library(factoextra) # clustering algorithms & visualization
fviz_cluster(result, data = df)
#19. Explore the cluster analysis result with various value of k like 3,4,5
k2 <- kmeans(df, centers = 2, nstart = 25)
k3 <- kmeans(df, centers = 3, nstart = 25)
k4 <- kmeans(df, centers = 4, nstart = 25)
k5 <- kmeans(df, centers = 5, nstart = 25)
library(animation)
km1<-kmeans.ani(df,3)
library(factoextra)
fviz_cluster(result, data = df)
k2 <- kmeans(df, centers = 2, nstart = 25)
k3 <- kmeans(df, centers = 3, nstart = 25)
k4 <- kmeans(df, centers = 4, nstart = 25)
k5 <- kmeans(df, centers = 5, nstart = 25)
# plots to compare
p1 <- fviz_cluster(k2, geom = "point", data = df) + ggtitle("k = 2")
p2 <- fviz_cluster(k3, geom = "point",  data = df) + ggtitle("k = 3")
p3 <- fviz_cluster(k4, geom = "point",  data = df) + ggtitle("k = 4")
p4 <- fviz_cluster(k5, geom = "point",  data = df) + ggtitle("k = 5")
library(gridExtra)
grid.arrange(p1, p2, p3, p4, nrow = 2)
install.packages("party")
library(party)
dt <- ctree(Species~., iris)
plt(dt)
library(party)
dt <- ctree(Species~., iris)
plot(dt)
iris
library(party)
iris
dt <- ctree(Species~Sepal.Length+.Width+Petal.Width+Petal.Length, iris)
library(party)
iris
dt <- ctree(Species~Sepal.Length+Sepal.Width+Petal.Width+Petal.Length, iris)
plot(dt)
library(party)
iris
dt <- ctree(Species~., iris)
plot(dt)
install.packages("rpart")
library(party)
iris
dt <- ctree(Species~., data = iris)
plot(dt)
install.packages("rpart.plot")
library(rpart)
library(rpart.plot)
dt <- rpart(Species~., data = iris, method = "class")
rpart.plot(dt)
library(rpart)
library(rpart.plot)
dt <- rpart(Species~., data = iris, method = "class")
rpart.plot(dt, extra = 101)
library(rpart)
library(rpart.plot)
dt <- rpart(Species~., data = iris, method = "class")
rpart.plot(dt, extra = 106)
library(rpart)
library(rpart.plot)
dt <- rpart(Species~., data = iris, method = "class")
rpart.plot(dt)
library(rpart)
library(rpart.plot)
dt <- rpart(Species~., data = iris, method = "class")
rpart.plot(dt)
rm(list=ls())
xs <- seq(-1,0.33,len=20)
xs
f <-  function(x) {3*x^2 + 2*x + 1}
# plot the function
plot(xs , f (xs), type="l",xlab="x",ylab=expression(1.2(x-2)^2 +3.2))
grad <- function(x){
3*2*x + 2
}
x <- 0.1
xtrace <- x
ftrace <- f(x)
stepFactor <- 0.01 # learning rate 'alpha'
for (step in 1:5000) {
x <- x - stepFactor*grad(x) # gradient descent update
xtrace <- c(xtrace,x) # update for graph
ftrace <- c(ftrace,f(x)) # update for graph
}
lines ( xtrace , ftrace , type="b",col="blue") # type=b (both points & lines)
text (0.5,6, "Gradient Descent",col="red",pos= 4)
# print final value of x
print(x) # x converges to 2.0
text(-0.33,1,"x=-0.333",col="red",pos=1)
text(-0.33,1.2,"(Global minimum)",col="red",pos=3)
rm(list = ls())
library(factoextra)
library(cluster)
df <- USArrests
df <- na.omit(df)
head(df)
df <- scale(df)
head(df)
dist_mat <- dist(df, method = 'euclidean')
hclust_complete <- hclust(dist_mat, method = 'complete')
plot(hclust_complete, cex=0.5, hang=-1)
cut <- cutree(hclust_complete, k=4)
abline(h =4 , col = 'red')
rect.hclust(hclust_complete , k = 4, border = 2:5)
rm(list = ls())
library(factoextra)
library(cluster)
df <- read.csv('seeds_K Means.csv')
setwd('/home/anish/Documents/WIN 21-22/CSE3506 EDA/19BCE1278_Anish/L9')
df <- read.csv('seeds_K Means.csv')
seeds_df <- read.csv('seeds_K Means.csv')
rm(list = ls())
library(factoextra)
library(cluster)
setwd('/home/anish/Documents/WIN 21-22/CSE3506 EDA/19BCE1278_Anish/L9')
seeds_df <- read.csv('seeds_K Means.csv')
seeds_df <- na.omit(df)
head(seeds_df)
seeds_df <- scale(seeds_df)
head(seeds_df)
dist_mat <- dist(seeds_df, method = 'euclidean')
rm(list = ls())
library(factoextra)
library(cluster)
setwd('/home/anish/Documents/WIN 21-22/CSE3506 EDA/19BCE1278_Anish/L9')
seeds_df <- read.csv('seeds_K Means.csv')
seeds_df <- na.omit(seeds_df)
head(seeds_df)
seeds_df <- scale(seeds_df)
head(seeds_df)
dist_mat <- dist(seeds_df, method = 'euclidean')
hclust_complete <- hclust(dist_mat, method = 'complete')
plot(hclust_complete, cex=0.5, hang=-1)
cut <- cutree(hclust_complete, k=4)
abline(h =4 , col = 'red')
rm(list = ls())
library(factoextra)
library(cluster)
setwd('/home/anish/Documents/WIN 21-22/CSE3506 EDA/19BCE1278_Anish/L9')
seeds_df <- read.csv('seeds_K Means.csv')
seeds_df <- na.omit(seeds_df)
head(seeds_df)
seeds_df <- scale(seeds_df)
head(seeds_df)
dist_mat <- dist(seeds_df, method = 'euclidean')
hclust_complete <- hclust(dist_mat, method = 'complete')
plot(hclust_complete, cex=0.5, hang=-1)
cut <- cutree(hclust_complete, k=4)
abline(h = 6 , col = 'red')
rect.hclust(hclust_complete , k = 6, border = 2:5)
rm(list = ls())
library(factoextra)
library(cluster)
setwd('/home/anish/Documents/WIN 21-22/CSE3506 EDA/19BCE1278_Anish/L9')
seeds_df <- read.csv('seeds_K Means.csv')
seeds_df <- na.omit(seeds_df)
head(seeds_df)
seeds_df <- scale(seeds_df)
head(seeds_df)
dist_mat <- dist(seeds_df, method = 'euclidean')
hclust_complete <- hclust(dist_mat, method = 'complete')
plot(hclust_complete, cex=0.5, hang=-1)
cut <- cutree(hclust_complete, k=6)
abline(h = 6 , col = 'red')
rect.hclust(hclust_complete , k = 6, border = 2:5)
cut <- cutree(hclust_complete, k=6)
abline(h = 6 , col = 'red')
rect.hclust(hclust_complete , k = 6, border = 2:5)
rm(list = ls())
library(factoextra)
library(cluster)
setwd('/home/anish/Documents/WIN 21-22/CSE3506 EDA/19BCE1278_Anish/L9')
seeds_df <- read.csv('seeds_K Means.csv')
seeds_df <- na.omit(seeds_df)
head(seeds_df)
seeds_df <- scale(seeds_df)
head(seeds_df)
dist_mat <- dist(seeds_df, method = 'euclidean')
hclust_complete <- hclust(dist_mat, method = 'complete')
plot(hclust_complete, cex=0.5, hang=-1)
cut <- cutree(hclust_complete, k=5)
abline(h = 5 , col = 'red')
rect.hclust(hclust_complete , k = 5, border = 2:5)
rm(list = ls())
library(factoextra)
library(cluster)
setwd('/home/anish/Documents/WIN 21-22/CSE3506 EDA/19BCE1278_Anish/L9')
seeds_df <- read.csv('seeds_K Means.csv')
seeds_df <- na.omit(seeds_df)
head(seeds_df)
seeds_df <- scale(seeds_df)
head(seeds_df)
dist_mat <- dist(seeds_df, method = 'euclidean')
hclust_complete <- hclust(dist_mat, method = 'complete')
plot(hclust_complete, cex=0.5, hang=-1)
cut <- cutree(hclust_complete, k=5)
abline(h = 5 , col = 'red')
rect.hclust(hclust_complete , k = 5, border = 2:5)
